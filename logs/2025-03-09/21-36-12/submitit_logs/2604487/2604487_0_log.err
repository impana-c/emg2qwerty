2025-03-09 21:36:17.478586: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741581377.499735 2604488 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741581377.506339 2604488 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-09 21:36:17.527891: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Global seed set to 1501
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
2025-03-09 21:36:27.803397: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741581387.823838 2604906 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741581387.830211 2604906 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-09 21:36:27.850998: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-09 21:36:27.920915: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741581387.941378 2604904 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741581387.947720 2604904 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-09 21:36:27.966207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-09 21:36:27.968686: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741581387.986571 2604905 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741581387.992858 2604905 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-09 21:36:28.013552: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-09 21:36:28.067025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741581388.087279 2604907 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741581388.093643 2604907 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-09 21:36:28.114128: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Missing logger folder: /home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/lightning_logs
Missing logger folder: /home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/lightning_logs
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

Missing logger folder: /home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/lightning_logs
Missing logger folder: /home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/lightning_logs
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  "lr_options": generate_power_seq(LEARNING_RATE_CIFAR, 11),
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask("01, 02, 11"),
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  self.nce_loss = AmdimNCELoss(tclip)
/home/bkwan27/anaconda3/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  return _target_(*args, **kwargs)

  | Name     | Type       | Params
----------------------------------------
0 | model    | Sequential | 2.4 M 
1 | ctc_loss | CTCLoss    | 0     
2 | metrics  | ModuleDict | 0     
----------------------------------------
2.4 M     Trainable params
0         Non-trainable params
2.4 M     Total params
9.564     Total estimated model params size (MB)
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1595: PossibleUserWarning: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
[rank3]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank0]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank2]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
Epoch 0, global step 30: 'val/CER' reached 119.16261 (best 119.16261), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=0-step=30.ckpt' as top 1
Epoch 1, global step 60: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=1-step=60.ckpt' as top 1
Epoch 2, global step 90: 'val/CER' was not in top 1
Epoch 3, global step 120: 'val/CER' was not in top 1
Epoch 4, global step 150: 'val/CER' was not in top 1
Epoch 5, global step 180: 'val/CER' was not in top 1
Epoch 6, global step 210: 'val/CER' was not in top 1
Epoch 7, global step 240: 'val/CER' was not in top 1
Epoch 8, global step 270: 'val/CER' was not in top 1
Epoch 9, global step 300: 'val/CER' was not in top 1
Epoch 10, global step 330: 'val/CER' was not in top 1
Epoch 11, global step 360: 'val/CER' was not in top 1
Epoch 12, global step 390: 'val/CER' was not in top 1
Epoch 13, global step 420: 'val/CER' was not in top 1
Epoch 14, global step 450: 'val/CER' was not in top 1
Epoch 15, global step 480: 'val/CER' was not in top 1
Epoch 16, global step 510: 'val/CER' was not in top 1
Epoch 17, global step 540: 'val/CER' was not in top 1
Epoch 18, global step 570: 'val/CER' was not in top 1
Epoch 19, global step 600: 'val/CER' was not in top 1
Epoch 20, global step 630: 'val/CER' was not in top 1
Epoch 21, global step 660: 'val/CER' was not in top 1
Epoch 22, global step 690: 'val/CER' was not in top 1
Epoch 23, global step 720: 'val/CER' reached 99.97784 (best 99.97784), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=23-step=720.ckpt' as top 1
Epoch 24, global step 750: 'val/CER' reached 98.33850 (best 98.33850), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=24-step=750.ckpt' as top 1
Epoch 25, global step 780: 'val/CER' reached 92.42357 (best 92.42357), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=25-step=780.ckpt' as top 1
Epoch 26, global step 810: 'val/CER' reached 89.87594 (best 89.87594), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=26-step=810.ckpt' as top 1
Epoch 27, global step 840: 'val/CER' reached 78.95436 (best 78.95436), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=27-step=840.ckpt' as top 1
Epoch 28, global step 870: 'val/CER' reached 71.99823 (best 71.99823), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=28-step=870.ckpt' as top 1
Epoch 29, global step 900: 'val/CER' reached 69.36198 (best 69.36198), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=29-step=900.ckpt' as top 1
Epoch 30, global step 930: 'val/CER' reached 60.50066 (best 60.50066), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=30-step=930.ckpt' as top 1
Epoch 31, global step 960: 'val/CER' reached 52.03811 (best 52.03811), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=31-step=960.ckpt' as top 1
Epoch 32, global step 990: 'val/CER' reached 51.77226 (best 51.77226), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=32-step=990.ckpt' as top 1
Epoch 33, global step 1020: 'val/CER' was not in top 1
Epoch 34, global step 1050: 'val/CER' reached 48.33850 (best 48.33850), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=34-step=1050.ckpt' as top 1
Epoch 35, global step 1080: 'val/CER' reached 44.57244 (best 44.57244), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=35-step=1080.ckpt' as top 1
Epoch 36, global step 1110: 'val/CER' was not in top 1
Epoch 37, global step 1140: 'val/CER' reached 41.75897 (best 41.75897), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=37-step=1140.ckpt' as top 1
Epoch 38, global step 1170: 'val/CER' was not in top 1
Epoch 39, global step 1200: 'val/CER' was not in top 1
Epoch 40, global step 1230: 'val/CER' reached 39.80948 (best 39.80948), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=40-step=1230.ckpt' as top 1
Epoch 41, global step 1260: 'val/CER' reached 38.10368 (best 38.10368), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=41-step=1260.ckpt' as top 1
Epoch 42, global step 1290: 'val/CER' reached 37.57200 (best 37.57200), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=42-step=1290.ckpt' as top 1
Epoch 43, global step 1320: 'val/CER' reached 35.35667 (best 35.35667), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=43-step=1320.ckpt' as top 1
Epoch 44, global step 1350: 'val/CER' was not in top 1
Epoch 45, global step 1380: 'val/CER' reached 34.31546 (best 34.31546), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=45-step=1380.ckpt' as top 1
Epoch 46, global step 1410: 'val/CER' reached 34.04962 (best 34.04962), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=46-step=1410.ckpt' as top 1
Epoch 47, global step 1440: 'val/CER' was not in top 1
Epoch 48, global step 1470: 'val/CER' reached 32.56535 (best 32.56535), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=48-step=1470.ckpt' as top 1
Epoch 49, global step 1500: 'val/CER' reached 31.41338 (best 31.41338), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=49-step=1500.ckpt' as top 1
Epoch 50, global step 1530: 'val/CER' reached 30.92601 (best 30.92601), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=50-step=1530.ckpt' as top 1
Epoch 51, global step 1560: 'val/CER' was not in top 1
Epoch 52, global step 1590: 'val/CER' reached 30.26141 (best 30.26141), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=52-step=1590.ckpt' as top 1
Epoch 53, global step 1620: 'val/CER' was not in top 1
Epoch 54, global step 1650: 'val/CER' was not in top 1
Epoch 55, global step 1680: 'val/CER' reached 28.84360 (best 28.84360), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=55-step=1680.ckpt' as top 1
Epoch 56, global step 1710: 'val/CER' reached 28.48915 (best 28.48915), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=56-step=1710.ckpt' as top 1
Epoch 57, global step 1740: 'val/CER' reached 27.89101 (best 27.89101), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=57-step=1740.ckpt' as top 1
Epoch 58, global step 1770: 'val/CER' reached 27.60301 (best 27.60301), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-09/21-36-12/job0_trainer.devices=4,user=single_user/checkpoints/epoch=58-step=1770.ckpt' as top 1
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")
Exception ignored in atexit callback: <function _exit_function at 0x70f8c9f00820>
Traceback (most recent call last):
  File "/home/bkwan27/anaconda3/lib/python3.10/multiprocessing/util.py", line 357, in _exit_function
Exception ignored in atexit callback: <function dump_compile_times at 0x76fe616e6320>
Traceback (most recent call last):
  File "/home/bkwan27/anaconda3/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 320, in dump_compile_times
Process SpawnProcess-2:
