2025-03-10 21:50:25.148187: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741668625.158951   38318 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741668625.162254   38318 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-10 21:50:25.173987: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Global seed set to 1501
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: /home/bkwan27/emg2qwerty/logs/2025-03-10/21-50-22/job0_trainer.devices=1,user=single_user/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  "lr_options": generate_power_seq(LEARNING_RATE_CIFAR, 11),
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask("01, 02, 11"),
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  self.nce_loss = AmdimNCELoss(tclip)
/home/bkwan27/anaconda3/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  return _target_(*args, **kwargs)

  | Name     | Type       | Params
----------------------------------------
0 | model    | Sequential | 5.3 M 
1 | ctc_loss | CTCLoss    | 0     
2 | metrics  | ModuleDict | 0     
----------------------------------------
5.3 M     Trainable params
0         Non-trainable params
5.3 M     Total params
21.173    Total estimated model params size (MB)
/home/bkwan27/anaconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
/home/bkwan27/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1595: PossibleUserWarning: The number of training batches (31) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
/home/bkwan27/anaconda3/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch 0, global step 31: 'val/CER' reached 1324.25781 (best 1324.25781), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-10/21-50-22/job0_trainer.devices=1,user=single_user/checkpoints/epoch=0-step=31.ckpt' as top 1
Epoch 1, global step 62: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-10/21-50-22/job0_trainer.devices=1,user=single_user/checkpoints/epoch=1-step=62.ckpt' as top 1
Epoch 2, global step 93: 'val/CER' was not in top 1
Epoch 3, global step 124: 'val/CER' was not in top 1
Epoch 4, global step 155: 'val/CER' was not in top 1
Epoch 5, global step 186: 'val/CER' was not in top 1
Epoch 6, global step 217: 'val/CER' was not in top 1
Epoch 7, global step 248: 'val/CER' was not in top 1
Epoch 8, global step 279: 'val/CER' was not in top 1
Epoch 9, global step 310: 'val/CER' was not in top 1
Epoch 10, global step 341: 'val/CER' was not in top 1
Epoch 11, global step 372: 'val/CER' was not in top 1
Epoch 12, global step 403: 'val/CER' was not in top 1
Epoch 13, global step 434: 'val/CER' reached 99.97784 (best 99.97784), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-10/21-50-22/job0_trainer.devices=1,user=single_user/checkpoints/epoch=13-step=434.ckpt' as top 1
Epoch 14, global step 465: 'val/CER' reached 99.86708 (best 99.86708), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-10/21-50-22/job0_trainer.devices=1,user=single_user/checkpoints/epoch=14-step=465.ckpt' as top 1
Epoch 15, global step 496: 'val/CER' was not in top 1
Epoch 16, global step 527: 'val/CER' was not in top 1
Epoch 17, global step 558: 'val/CER' was not in top 1
Epoch 18, global step 589: 'val/CER' reached 99.73416 (best 99.73416), saving model to '/home/bkwan27/emg2qwerty/logs/2025-03-10/21-50-22/job0_trainer.devices=1,user=single_user/checkpoints/epoch=18-step=589.ckpt' as top 1
Epoch 19, global step 620: 'val/CER' was not in top 1
Epoch 20, global step 651: 'val/CER' was not in top 1
Epoch 21, global step 682: 'val/CER' was not in top 1
Epoch 22, global step 713: 'val/CER' was not in top 1
Epoch 23, global step 744: 'val/CER' was not in top 1
Epoch 24, global step 775: 'val/CER' was not in top 1
Epoch 25, global step 806: 'val/CER' was not in top 1
Epoch 26, global step 837: 'val/CER' was not in top 1
Epoch 27, global step 868: 'val/CER' was not in top 1
Epoch 28, global step 899: 'val/CER' was not in top 1
Epoch 29, global step 930: 'val/CER' was not in top 1
`Trainer.fit` stopped: `max_epochs=30` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
